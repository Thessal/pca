{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d730c65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Data Generation and Partitioning ---\n",
      "\n",
      "--- 2. Federated Vertical PCA Process ---\n",
      "Party A: Computing local covariance matrix.\n",
      "Party B: Computing local covariance matrix.\n",
      "Coordinator: Securely computing cross-covariance (simulation)...\n",
      "Coordinator: Assembling global covariance matrix.\n",
      "Coordinator: PCA complete. Found 3 principal components.\n",
      "\n",
      "Federated Principal Components (shape: (10, 3)):\n",
      " [[-0.42051181 -0.0658889  -0.48382616]\n",
      " [ 0.61660298 -0.01977591 -0.1280178 ]\n",
      " [ 0.44655481  0.09503789 -0.40856453]\n",
      " [-0.06088068  0.10191074 -0.47266772]\n",
      " [-0.25086277 -0.04910853 -0.40891301]\n",
      " [-0.00828997  0.36740283  0.11230176]\n",
      " [-0.35299572  0.07244922  0.17725084]\n",
      " [ 0.17023818 -0.39749757  0.20188641]\n",
      " [ 0.09521892  0.75222408 -0.06324287]\n",
      " [-0.11915709  0.33069444  0.32122695]]\n",
      "\n",
      "--- 3. Validation with Centralized PCA ---\n",
      "Centralized Principal Components (shape: (10, 3)):\n",
      " [[-0.42051181 -0.0658889  -0.48382616]\n",
      " [ 0.61660298 -0.01977591 -0.1280178 ]\n",
      " [ 0.44655481  0.09503789 -0.40856453]\n",
      " [-0.06088068  0.10191074 -0.47266772]\n",
      " [-0.25086277 -0.04910853 -0.40891301]\n",
      " [-0.00828997  0.36740283  0.11230176]\n",
      " [-0.35299572  0.07244922  0.17725084]\n",
      " [ 0.17023818 -0.39749757  0.20188641]\n",
      " [ 0.09521892  0.75222408 -0.06324287]\n",
      " [-0.11915709  0.33069444  0.32122695]]\n",
      "\n",
      "✅ Verification successful: Federated results match centralized PCA.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class VerticalParty:\n",
    "    \"\"\"\n",
    "    Represents a party holding a vertical partition of the data (a subset of features).\n",
    "    \"\"\"\n",
    "    def __init__(self, name, data):\n",
    "        if not isinstance(data, np.ndarray):\n",
    "            raise TypeError(\"Data must be a numpy array.\")\n",
    "        self.name = name\n",
    "        # Center the data upon initialization\n",
    "        self.data = data - np.mean(data, axis=0)\n",
    "        self.n_samples, self.n_features = self.data.shape\n",
    "\n",
    "    def compute_local_covariance(self):\n",
    "        \"\"\"\n",
    "        Computes the covariance matrix for this party's features.\n",
    "        \"\"\"\n",
    "        print(f\"Party {self.name}: Computing local covariance matrix.\")\n",
    "        return self.data.T @ self.data\n",
    "\n",
    "class Coordinator:\n",
    "    \"\"\"\n",
    "    Represents the server or coordinator that assembles the final matrix and runs PCA.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.global_covariance = None\n",
    "        self.principal_components = None\n",
    "\n",
    "    def securely_compute_cross_covariance(self, party_A, party_B):\n",
    "        \"\"\"\n",
    "        *** SIMULATION ONLY ***\n",
    "        This function simulates a secure multi-party computation protocol\n",
    "        (e.g., using Homomorphic Encryption) to compute X_A^T * X_B.\n",
    "        In a real-world scenario, this would be a complex cryptographic exchange.\n",
    "        \"\"\"\n",
    "        print(\"Coordinator: Securely computing cross-covariance (simulation)...\")\n",
    "        # In reality, parties would not share self.data.\n",
    "        # This is a placeholder for the result of the secure protocol.\n",
    "        cross_covariance = party_A.data.T @ party_B.data\n",
    "        return cross_covariance\n",
    "\n",
    "    def run_vertical_pca(self, party_A, party_B, n_components):\n",
    "        \"\"\"\n",
    "        Orchestrates the entire vertically partitioned PCA process.\n",
    "        \"\"\"\n",
    "        # 1. Get local covariances\n",
    "        cov_AA = party_A.compute_local_covariance()\n",
    "        cov_BB = party_B.compute_local_covariance()\n",
    "\n",
    "        # 2. Get cross-covariance through secure computation\n",
    "        cov_AB = self.securely_compute_cross_covariance(party_A, party_B)\n",
    "        cov_BA = cov_AB.T\n",
    "\n",
    "        # 3. Assemble the full covariance matrix\n",
    "        print(\"Coordinator: Assembling global covariance matrix.\")\n",
    "        # np.block provides a clean way to build block matrices\n",
    "        self.global_covariance = np.block([\n",
    "            [cov_AA, cov_AB],\n",
    "            [cov_BA, cov_BB]\n",
    "        ])\n",
    "\n",
    "        # 4. Perform PCA on the global matrix\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(self.global_covariance)\n",
    "        sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "        self.principal_components = eigenvectors[:, sorted_indices][:, :n_components]\n",
    "        print(f\"Coordinator: PCA complete. Found {self.principal_components.shape[1]} principal components.\")\n",
    "        return self.principal_components\n",
    "\n",
    "# --- Simulation ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Generate and vertically partition data\n",
    "    print(\"--- 1. Data Generation and Partitioning ---\")\n",
    "    np.random.seed(42)\n",
    "    # 150 samples, 10 features total\n",
    "    full_data = np.random.rand(150, 10)\n",
    "\n",
    "    # Party A gets the first 4 features, Party B gets the next 6\n",
    "    party_A_data = full_data[:, 0:4]\n",
    "    party_B_data = full_data[:, 4:10]\n",
    "\n",
    "    party_A = VerticalParty(name=\"A\", data=party_A_data)\n",
    "    party_B = VerticalParty(name=\"B\", data=party_B_data)\n",
    "\n",
    "    # 2. Coordinator runs the federated PCA process\n",
    "    print(\"\\n--- 2. Federated Vertical PCA Process ---\")\n",
    "    coordinator = Coordinator()\n",
    "    n_principal_components = 3\n",
    "    federated_pcs = coordinator.run_vertical_pca(party_A, party_B, n_components=3)\n",
    "    print(f\"\\nFederated Principal Components (shape: {federated_pcs.shape}):\\n\", federated_pcs)\n",
    "\n",
    "    # 3. Validation: Compare with centralized PCA\n",
    "    print(\"\\n--- 3. Validation with Centralized PCA ---\")\n",
    "    centralized_data = full_data - np.mean(full_data, axis=0)\n",
    "    centralized_cov = centralized_data.T @ centralized_data\n",
    "    eig_vals, eig_vecs = np.linalg.eigh(centralized_cov)\n",
    "    sorted_idx = np.argsort(eig_vals)[::-1]\n",
    "    centralized_pcs = eig_vecs[:, sorted_idx][:, :n_principal_components]\n",
    "    print(f\"Centralized Principal Components (shape: {centralized_pcs.shape}):\\n\", centralized_pcs)\n",
    "\n",
    "    # Check if the results are close (they should be identical up to sign flips)\n",
    "    assert np.allclose(np.abs(federated_pcs), np.abs(centralized_pcs))\n",
    "    print(\"\\n✅ Verification successful: Federated results match centralized PCA.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f3bb08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
